{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f04d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "#tf.random.set_seed(1)\n",
    "\n",
    "def get_feat_and_labels(filename, as_tensor = True):\n",
    "    data = pd.read_csv(filename)\n",
    "\n",
    "    data[\"Angle\"] = np.abs(np.arctan2(data[\"OppY\"], data[\"OppX\"]))\n",
    "    data[\"OppY\"] = np.abs(data[\"OppY\"])\n",
    "    data = data[[\"Angle\",  \"DistanceToGoal\", \"DistanceToOpp\",  \"OppX\", \"OppY\",\"Success\"]]\n",
    "    \n",
    "    #Converting text yes no to int.\n",
    "    if(data[\"Success\"].dtype == object):\n",
    "        data[\"Success\"] = (data[\"Success\"] == \"YES\")*1\n",
    "    \n",
    "    if(as_tensor):\n",
    "        return tf.convert_to_tensor(data.drop(columns=\"Success\"),dtype=tf.float32), \\\n",
    "                tf.convert_to_tensor(data[\"Success\"],dtype=tf.float32),\\\n",
    "                data.copy() \n",
    "    else:\n",
    "        return data.drop(columns=\"Success\"), data[\"Success\"], data.copy() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f41ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code used to create training data\"\"\"\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def printCount(data):\n",
    "    if type(data) == pd.DataFrame:\n",
    "        success_no = data[data['Success'] == 0]\n",
    "        success_yes = data[data['Success'] == 1]\n",
    "    else:\n",
    "        success_no = data[data == 0]\n",
    "        success_yes = data[data == 1]\n",
    "    print('success no:', success_no.shape[0])\n",
    "    print('success yes:', success_yes.shape[0])\n",
    "    \n",
    "def get_data(names):\n",
    "    _, _, original_data = get_feat_and_labels(names[0], as_tensor=False)\n",
    "    \n",
    "    print(names[0])#,original_data)\n",
    "    printCount(original_data)\n",
    "    for n in names[1:]:\n",
    "        _, _, d = get_feat_and_labels(n, as_tensor=False)        \n",
    "        print(n)#,_)\n",
    "        printCount(d)\n",
    "        original_data = pd.concat([original_data, d],axis=0)\n",
    "    \n",
    "    printCount(original_data)\n",
    "    return original_data\n",
    "\n",
    "# data_names = [\n",
    "#                \"data\\\\\\MotionTrainingData\\CanShootStillLocal3x.csv\",#still\n",
    "                \n",
    "#                 \"data\\\\\\MotionTrainingData\\CanShootTolLocal2x.csv\",#Motion\n",
    "#                 \"data\\\\MotionTrainingData\\CanShootTolLocal3x.csv\",#Motion\n",
    "#                 \"data\\\\MotionTrainingData\\CanShootTolLocal4x.csv\",#Motion\n",
    "                \n",
    "#                 \"data\\\\\\MixedData\\Testfeb8num3\\CanShoot2MotionTol2x.csv\",#Motion\n",
    "#                 \"data\\\\\\MixedData\\Testfeb8num3\\CanShoot2MotionTol3x.csv\",#Motion\n",
    "#                 \"data\\\\\\MixedData\\Testfeb8num3\\CanShoot2MotionTol4x.csv\",#Motion\n",
    "                \n",
    "#                 \"data\\\\MixedData\\Testfeb8num3\\CanShoot2plus75tolerance.csv\",#still\n",
    "#                 \"data\\\\MixedData\\Testfeb8num3\\CanShoot2Tol3x.csv\",#still\n",
    "#                 \"data\\\\MixedData\\Testfeb8num3\\CanShoot2Tol4x.csv\",#still\n",
    "#                 \"data\\\\MixedData\\Testfeb8num3\\CanShoot2Tolerance2x.csv\",#still\n",
    "                \n",
    "#                 \"data\\\\MixedData\\Originals\\CanShoot2Behavior.csv\",#motion\n",
    "                \n",
    "#                 \"data\\\\MixedData\\Originals\\CanShoot2Bottom.csv\",#still\n",
    "#                 \"data\\\\MixedData\\Originals\\CanShoot2Upper.csv\",#still\n",
    "#                 \"data\\\\MixedData\\Originals\\CanShoot2Center.csv\",#still\n",
    "#                 \"data\\\\MixedData\\Originals\\CanShoot2Mid.csv\"#still\n",
    "\n",
    "#              ]\n",
    "\n",
    "simple_load = True\n",
    "\n",
    "if(simple_load):  \n",
    "    can_shoot_features, can_shoot_labels, _ = get_feat_and_labels(\"TrainFinal.csv\" )\n",
    "    cs_feat_valid, cs_labels_valid, _ = get_feat_and_labels(\"ValidFinal.csv\" )\n",
    "    \n",
    "else: #This is how the stratified train/valid split was created.\n",
    "    data_og = get_data(data_names)\n",
    "\n",
    "    can_shoot_features, cs_feat_valid, can_shoot_labels, cs_labels_valid = train_test_split(data_og.drop(columns=\"Success\"), data_og[\"Success\"], test_size=0.33, random_state=3, stratify=data_og[\"Success\"])\n",
    "\n",
    "    printCount(can_shoot_labels)\n",
    "    printCount(cs_labels_valid)\n",
    "\n",
    "    can_shoot_features = tf.convert_to_tensor(can_shoot_features, dtype=tf.float32) \n",
    "    can_shoot_labels = tf.convert_to_tensor(can_shoot_labels, dtype=tf.float32)  \n",
    "\n",
    "    cs_feat_valid = tf.convert_to_tensor(cs_feat_valid, dtype=tf.float32) \n",
    "    cs_labels_valid = tf.convert_to_tensor(cs_labels_valid, dtype=tf.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Write dataframe back to csv after processing data\"\"\"\n",
    "def writeToCSV(features, labels, name):\n",
    "    to_csv_var = pd.DataFrame(tf.concat([features, tf.expand_dims(labels, axis=1)], axis=1).numpy(),\n",
    "                                       columns=[\"Angle\",  \"DistanceToGoal\", \"DistanceToOpp\",  \"OppX\", \"OppY\",\"Success\"])\n",
    "    to_csv_var[\"Success\"] = to_csv_var[\"Success\"]==1\n",
    "    to_csv_var.to_csv(name, index=False)\n",
    "    \n",
    "# writeToCSV(can_shoot_features, can_shoot_labels, \"TrainFinal.csv\" )\n",
    "# writeToCSV(cs_feat_valid, cs_labels_valid, \"ValidFinal.csv\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e969a",
   "metadata": {},
   "source": [
    "# Train Model loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f4aeb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "num_feats = can_shoot_features.shape[1]\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.BatchNormalization(input_dim=num_feats),\n",
    "  tf.keras.layers.Dense(6, activation='relu'),\n",
    " \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(3, activation='swish'),\n",
    "\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.05),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Recall(), tf.keras.metrics.Precision()], \n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=75, min_lr=0.001)\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    can_shoot_features,\n",
    "    can_shoot_labels,\n",
    "    batch_size=16,\n",
    "    epochs = 64,   \n",
    "    validation_data= (cs_feat_valid, cs_labels_valid ),\n",
    "    callbacks=[reduce_lr] \n",
    ")\n",
    "\n",
    "\n",
    "#add early stopping\n",
    "early_stop= tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=50, verbose=0,\n",
    "    mode='min', baseline=None, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    can_shoot_features,\n",
    "    can_shoot_labels,\n",
    "    batch_size=16,\n",
    "    epochs = 512,   \n",
    "    validation_data= (cs_feat_valid, cs_labels_valid ),\n",
    "    callbacks=[reduce_lr, early_stop] \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4dcc1f",
   "metadata": {},
   "source": [
    "# Summary of Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ae2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAcc_Rec_Prec(conf_mat):\n",
    "    accuracy = (conf_mat[0,0]+conf_mat[1,1])/np.sum(conf_mat)\n",
    "\n",
    "    recall = conf_mat[1,1]/sum(conf_mat[1,:])\n",
    "\n",
    "    precision = conf_mat[1,1]/sum(conf_mat[:,1])\n",
    "    \n",
    "    return accuracy, recall, precision\n",
    "\n",
    "def getPosNeg(prediction, actual):\n",
    "    tp,fp,tn,fn = 0,0,0,0\n",
    "    for i in range(len(prediction)):\n",
    "        if(np.round(prediction[i]) == 1):\n",
    "            if(np.round(prediction[i]) == actual[i]):\n",
    "                tp+=1\n",
    "            else:\n",
    "                fp+=1\n",
    "        else:\n",
    "            if(np.round(prediction[i]) == actual[i]):\n",
    "                tn+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "    return tp,fp,tn,fn\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14327ff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(can_shoot_features, can_shoot_labels)\n",
    "print(\"Final train_ loss, train_acc:\", results)\n",
    "\n",
    "results = model.evaluate(cs_feat_valid, cs_labels_valid)\n",
    "print(\"Final val_ loss, val_acc:\", results)\n",
    "\n",
    "out=model.predict(cs_feat_valid)\n",
    "# out = tf.squeeze(out)\n",
    "\n",
    "conf_mat = tf.math.confusion_matrix(cs_labels_valid, np.round(out))\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366fe8f2",
   "metadata": {},
   "source": [
    "# Logistic Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0612a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "lr_model = LogisticRegression(solver='liblinear') #,random_state=0)\n",
    "\n",
    "#Build logistic regressor on Training Set\n",
    "lr_model.fit(can_shoot_features, can_shoot_labels)\n",
    "\n",
    "#Output results on Validation set\n",
    "output_lr = lr_model.predict(cs_feat_valid)\n",
    "\n",
    "lr_conf_mat = confusion_matrix(cs_labels_valid, output_lr)\n",
    "\n",
    "lr_acc, lr_rec, lr_prec = getAcc_Rec_Prec(lr_conf_mat)\n",
    "\n",
    "print(\"LogisticRegression_Accuracy: \",lr_acc)\n",
    "print(\"LogisticRegression_Recall: \", lr_rec)\n",
    "print(\"LogisticRegression_Precision: \", lr_prec)\n",
    "print(lr_conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc86935",
   "metadata": {},
   "source": [
    "# Save model if wanted. Specify folder directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c157fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if(save):\n",
    "    write_name='Feb13StratifiedModel'\n",
    "    model.save(write_name, save_format='tf')\n",
    "    import subprocess\n",
    "    #Prints out information needed on C++ side\n",
    "    subprocess.check_output(\"saved_model_cli show --dir \"+write_name+\" --tag_set serve --signature_def serving_default\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce3b92d",
   "metadata": {},
   "source": [
    "# Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a615e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_trained_model = True\n",
    "if(load_trained_model):\n",
    "    model = tf.keras.models.load_model('Feb13StratifiedModel/')\n",
    "    \n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6993a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = [\"data\\\\Testing\\CanShoot2MotionTol2x.csv\",\n",
    "              \"data\\\\Testing\\CanShoot2MotionTol3x.csv\",\n",
    "              \"data\\\\Testing\\CanShoot2MotionTol4x.csv\",\n",
    "              \"data\\\\Testing\\CanShootStillTol2x.csv\"\n",
    "             ]\n",
    "test_feat, test_label, _ = get_feat_and_labels(test_names[0], as_tensor=False)\n",
    "data_test = test_feat\n",
    "data_label = test_label\n",
    "for n in test_names[1:]:\n",
    "    f,l,_ = get_feat_and_labels(n, as_tensor=False)\n",
    "    test_feat = pd.concat([test_feat, f], axis = 0)\n",
    "    test_label = pd.concat([test_label, l], axis = 0)\n",
    "    \n",
    "\n",
    "test_feat = tf.convert_to_tensor(test_feat, dtype=tf.float32)\n",
    "test_label = tf.convert_to_tensor(test_label, dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "results = model.evaluate(test_feat, test_label)\n",
    "\n",
    "print(\"Final train_ loss, train_acc:\", results)\n",
    "\n",
    "test_out = model.predict(test_feat)\n",
    "\n",
    "test_conf = tf.math.confusion_matrix(test_label, np.round(test_out))\n",
    "\n",
    "print(test_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92882c",
   "metadata": {},
   "source": [
    "# Logistic Regression models performance on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b582926",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n_____________________________\\n|Logistic Regression Results|\")\n",
    "output_lr = lr_model.predict(test_feat)\n",
    "\n",
    "lr_conf_mat = confusion_matrix(test_label, output_lr)\n",
    "print(lr_conf_mat)\n",
    "\n",
    "lr_acc, lr_rec, lr_prec = getAcc_Rec_Prec(lr_conf_mat)\n",
    "\n",
    "print(\"LogisticRegression_Accuracy: \",lr_acc)\n",
    "print(\"LogisticRegression_Recall: \", lr_rec)\n",
    "print(\"LogisticRegression_Precision: \", lr_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa1fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=100, suppress=True)\n",
    "\n",
    "fun = lr_model.coef_[0]\n",
    "print('Coefficients: ',fun)\n",
    "print(\"intercept: \", lr_model.intercept_)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03e9aa504c6f5437b02ae694862f139df05f8b492dcd0e5dc12aebb102e336f0"
  },
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
