{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed745a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "#tf.random.set_seed(1)\n",
    "\n",
    "def get_feat_and_labels(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "\n",
    "    data[\"Angle\"] = np.abs(np.arctan2(data[\"OppY\"], data[\"OppX\"]))\n",
    "    data[\"OppY\"] = np.abs(data[\"OppY\"])\n",
    "    data = data[[\"Angle\",  \"DistanceToGoal\", \"DistanceToOpp\",  \"OppX\", \"OppY\",\"Success\"]]\n",
    "    \n",
    "    #Converting text yes no to int.\n",
    "    if(data[\"Success\"].dtype == object):\n",
    "        data[\"Success\"] = (data[\"Success\"] == \"YES\")*1\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printYesNoCount(data):\n",
    "    if type(data) == pd.DataFrame:\n",
    "        success_no = data[data['Success'] == 0]\n",
    "        success_yes = data[data['Success'] == 1]\n",
    "    else:\n",
    "        success_no = data[data == 0]\n",
    "        success_yes = data[data == 1]\n",
    "    print('success no:', success_no.shape[0])\n",
    "    print('success yes:', success_yes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf458a18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Code used to create training data\"\"\"\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "def get_data(names):\n",
    "    original_data = get_feat_and_labels(names[0])\n",
    "    \n",
    "    for n in names[1:]:\n",
    "        d = get_feat_and_labels(n)        \n",
    "        original_data = pd.concat([original_data, d],axis=0)\n",
    "    \n",
    "    #printYesNoCount(original_data)\n",
    "    return original_data\n",
    "\n",
    "# data_names = [\n",
    "#                 \"..\\MotionTrainingData\\CanShootTolLocal2x.csv\",\n",
    "#                 \"..\\MotionTrainingData\\CanShootTolLocal3x.csv\",\n",
    "#                 \"..\\MotionTrainingData\\CanShootTolLocal4x.csv\",\n",
    "#                 \"..\\\\MixedData\\Testfeb8num3\\CanShoot2MotionTol2x.csv\",\n",
    "#                 \"..\\\\MixedData\\Testfeb8num3\\CanShoot2MotionTol3x.csv\",\n",
    "#                 \"..\\\\MixedData\\Testfeb8num3\\CanShoot2MotionTol4x.csv\",\n",
    "#                 \"..\\\\MixedData\\Testfeb8num3\\CanShoot2plus75tolerance.csv\",\n",
    "#                 \"..\\\\MixedData\\Testfeb8num3\\CanShoot2Tol3x.csv\",\n",
    "#                 \"..\\\\MixedData\\Testfeb8num3\\CanShoot2Tol4x.csv\",\n",
    "\n",
    "#                 \"..\\\\MixedData\\Testfeb8num3\\CanShoot2Tolerance2x.csv\",\n",
    "#                 \"..\\\\MixedData\\Originals\\CanShoot2Behavior.csv\",\n",
    "#                 \"..\\\\MixedData\\Originals\\CanShoot2Bottom.csv\",\n",
    "#                 \"..\\\\MixedData\\Originals\\CanShoot2Upper.csv\",\n",
    "#                 \"..\\\\MixedData\\Originals\\CanShoot2Mid.csv\"\n",
    "    \n",
    "#              ]\n",
    "data_names = [\n",
    "               \"data\\\\Training\\MotionTrainingData\\CanShootStillLocal3x.csv\",\n",
    "                \n",
    "                \"data\\\\Training\\MotionTrainingData\\CanShootTolLocal2x.csv\",\n",
    "                \"data\\\\Training\\MotionTrainingData\\CanShootTolLocal3x.csv\",\n",
    "                \"data\\\\Training\\MotionTrainingData\\CanShootTolLocal4x.csv\",\n",
    "                \n",
    "                \"data\\\\Training\\\\MixedData\\Testfeb8num3\\CanShoot2MotionTol2x.csv\",\n",
    "                \"data\\\\Training\\\\MixedData\\Testfeb8num3\\CanShoot2MotionTol3x.csv\",\n",
    "                \"data\\\\Training\\\\MixedData\\Testfeb8num3\\CanShoot2MotionTol4x.csv\",\n",
    "                \n",
    "                \"data\\\\Training\\\\MixedData\\Testfeb8num3\\CanShoot2plus75tolerance.csv\",\n",
    "                \"data\\\\Training\\\\MixedData\\Testfeb8num3\\CanShoot2Tol3x.csv\",\n",
    "                \"data\\\\Training\\\\MixedData\\Testfeb8num3\\CanShoot2Tol4x.csv\",\n",
    "                \"data\\\\Training\\\\MixedData\\Testfeb8num3\\CanShoot2Tolerance2x.csv\",\n",
    "                \n",
    "                \"data\\\\Training\\\\MixedData\\Originals\\CanShoot2Behavior.csv\",\n",
    "                \n",
    "                \"data\\\\Training\\\\MixedData\\Originals\\CanShoot2Bottom.csv\",\n",
    "                \"data\\\\Training\\\\MixedData\\Originals\\CanShoot2Upper.csv\",\n",
    "                \"data\\\\Training\\\\MixedData\\Originals\\CanShoot2Center.csv\",\n",
    "                \"data\\\\Training\\\\MixedData\\Originals\\CanShoot2Mid.csv\"\n",
    "\n",
    "             ]\n",
    "\n",
    "    \n",
    "#Load all data  normally the stratified train/valid split would be used created.\n",
    "train_data = get_data(data_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eeac1f",
   "metadata": {},
   "source": [
    "# Train Model loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab88b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model(num_feats):\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.BatchNormalization(input_dim=num_feats),\n",
    "      tf.keras.layers.Dense(6, activation='relu'),\n",
    "\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(3, activation='swish'),\n",
    "\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid') \n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.05),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "        metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Recall(), tf.keras.metrics.Precision()], \n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "loud_mode = False\n",
    "def train_model(model, inputs, targets):\n",
    "    #Model early stops on a validation loss on a split of the training data\n",
    "    \n",
    "    #Reduce lr on loss instead of val_los\n",
    "    from keras.callbacks import ReduceLROnPlateau\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5,\n",
    "                              patience=75, min_lr=0.001)\n",
    "    model.fit(\n",
    "        inputs,\n",
    "        targets,\n",
    "        batch_size=16,\n",
    "        epochs = 64,   \n",
    "        callbacks=[reduce_lr],\n",
    "        verbose = loud_mode\n",
    "    )\n",
    "\n",
    "\n",
    "    #Early stop on loss instead of val_loss.\n",
    "    early_stop= tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss', min_delta=0, patience=50, verbose=0,\n",
    "        mode='min', baseline=None, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        inputs,\n",
    "        targets,\n",
    "        batch_size=16,\n",
    "        epochs = 512,   \n",
    "        callbacks=[reduce_lr, early_stop] ,\n",
    "        verbose = loud_mode\n",
    "    )\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72167d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResults(name, acc_per_fold, train_idx, test_idx):\n",
    "    output_file = open(f'CrossValidationResults\\\\{name}.csv', \"w\")\n",
    "    output_file.write('Fold,Accuracy,Train_size,Test_size'+'\\n')\n",
    "    \n",
    "    print(f'------------------------------------------------------------------------\\n{name}\\nScore per fold:')\n",
    "    for i in range(0, len(acc_per_fold)):\n",
    "        print(f'> Fold {i+1} - Accuracy: {acc_per_fold[i]}%')\n",
    "        output_file.write(f'{i+1},{acc_per_fold[i]},{len(train_idx[i])},{len(test_idx[i])}'+'\\n')\n",
    "    \n",
    "    #output_file.write(f'{np.mean(acc_per_fold)},{np.std(acc_per_fold)}'+'\\n')\n",
    "    output_file.close()   \n",
    "    \n",
    "    #print('------------------------------------------------------------------------\\nAverage scores for all folds:')\n",
    "    #print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad2edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#referenced:\n",
    "#https://medium.com/analytics-vidhya/using-the-corrected-paired-students-t-test-for-comparing-the-performance-of-machine-learning-dc6529eaa97f\n",
    "def CorrectedResampledPairedT_Test(nn_acc_per_fold, lr_acc_per_fold, trains, tests):\n",
    "    diff = [y - x for y, x in zip(nn_acc_per_fold, lr_acc_per_fold)]\n",
    "    \n",
    "    mean_diff = np.mean(diff)\n",
    "    s2 = np.var(diff, ddof=1)\n",
    "    \n",
    "    #Size of folds\n",
    "    n1 = np.mean(trains)\n",
    "    n2 = np.mean(tests)\n",
    "    print(f'n1:{n1} n2:{n2}')\n",
    "    \n",
    "    #total number of folds\n",
    "    K = len(diff)\n",
    "    S2 = (1/K + n2/n1) * s2\n",
    "    \n",
    "    m_s =  mean_diff / np.sqrt(S2)\n",
    "    \n",
    "    from scipy.stats import t\n",
    "    \n",
    "    #Compute p-value and plot the results \n",
    "    Pvalue = ((1 - t.cdf(np.abs(m_s), K-1))*2.0)\n",
    "    \n",
    "    print(m_s)\n",
    "    print(Pvalue)\n",
    "    print(\"T\", t.cdf(np.abs(m_s), K-1))\n",
    "    #print(\"2.276003475\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c046d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "#based on: \n",
    "# https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def ten_ten_fold_cross_val():\n",
    "    # Combine all of training data for cross_validation\n",
    "    fold_info = []\n",
    "    train_inf = []\n",
    "    test_inf = []\n",
    "    \n",
    "    nn_acc_per_fold= []    \n",
    "    lr_acc_per_fold= []\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    fold_no = 1\n",
    "    \n",
    "    inputs = train_data.drop(columns=\"Success\")\n",
    "    targets = train_data[\"Success\"]\n",
    "\n",
    "    print(inputs.shape)\n",
    "\n",
    "    #kfold = KFold(n_splits=10, shuffle=True)\n",
    "    kfold = RepeatedStratifiedKFold(n_splits=10, n_repeats=10)#,random_state=0)\n",
    "        \n",
    "    for train, test in kfold.split(inputs, targets):\n",
    "        print(f'------------------------------------------------------------------------\\nTraining for fold {fold_no} ...')\n",
    "        #Store train test split\n",
    "        fold_info.append([train,test])\n",
    "        train_inf.append(train)\n",
    "        test_inf.append(test)\n",
    "        print(f'Length of train: {len(train)} \\t length of test: {len(test)}')\n",
    "\n",
    "        # -- Neural Network --\n",
    "        tf.keras.backend.clear_session()\n",
    "        cv_nn_model = get_model(inputs.shape[1])\n",
    "\n",
    "        #Train model using train split.\n",
    "        train_model(cv_nn_model, inputs.iloc[train], targets.iloc[train])\n",
    "\n",
    "        # -- Test --\n",
    "        nn_scores = cv_nn_model.evaluate(inputs.iloc[test], targets.iloc[test], verbose=0)\n",
    "        nn_acc_per_fold.append(nn_scores[1] * 100)\n",
    "\n",
    "        print(f'NN: Score for fold {fold_no}: {cv_nn_model.metrics_names[1]} of {nn_scores[1]*100}%; {cv_nn_model.metrics_names[0]} of {nn_scores[0]}')\n",
    "\n",
    "\n",
    "\n",
    "        # -- Logistic regressor --\n",
    "        #Fit logistic regressor on train split\n",
    "        lr_model = LogisticRegression(solver='liblinear')#, random_state=0)\n",
    "        lr_model.fit(inputs.iloc[train], targets.iloc[train])\n",
    "\n",
    "        #Get accuracy\n",
    "        output_lr = lr_model.predict(inputs.iloc[test])\n",
    "        lr_scores = accuracy_score(targets.iloc[test], output_lr)\n",
    "        lr_acc_per_fold.append(lr_scores*100)\n",
    "\n",
    "        print(f'LR: Score for fold {fold_no}: binary_accuracy of {lr_scores*100}%')\n",
    "\n",
    "        # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "\n",
    "        \n",
    "    # == Provide average scores ==\n",
    "    #Write NN to file\n",
    "    printResults(\"NeuralNetwork\", nn_acc_per_fold, train_inf, test_inf)\n",
    "    \n",
    "    #Write LR to file\n",
    "    printResults(\"LinearLogisticRegression\", lr_acc_per_fold, train_inf,test_inf)\n",
    "    \n",
    "    #CorrectedResampledPairedT_Test(nn_acc_per_fold, lr_acc_per_fold, fold_info)\n",
    "    \n",
    "    return nn_acc_per_fold, lr_acc_per_fold, train_inf, test_inf, fold_info\n",
    "  \n",
    "nn_acc, lr_acc, trains, tests, f_inf = ten_ten_fold_cross_val()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_len =[]\n",
    "tests_len = []\n",
    "for i in range(len(trains)):\n",
    "    trains_len.append(len(trains[i]))\n",
    "    tests_len.append(len(tests[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb744d37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "CorrectedResampledPairedT_Test(nn_acc, lr_acc, trains_len, tests_len)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03e9aa504c6f5437b02ae694862f139df05f8b492dcd0e5dc12aebb102e336f0"
  },
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
